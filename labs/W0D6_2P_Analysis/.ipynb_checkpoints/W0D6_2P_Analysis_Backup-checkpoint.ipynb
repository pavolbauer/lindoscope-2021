{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When kernel error appears, type python ipykernel -m install --user\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import hdf5storage\n",
    "import mpld3 #install conda-forge\n",
    "mpld3.enable_notebook() # allows zooming in plots\n",
    "from matplotlib import gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "import math\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "%matplotlib inline\n",
    "from scipy import signal as sig\n",
    "from shapely.geometry import Polygon #install conda-forge\n",
    "import uncertainties as unc #install pip\n",
    "import uncertainties.unumpy as unp\n",
    "import sys\n",
    "sys.path.append(\"../../src/W0D6_2P_Analysis\")\n",
    "from nimatch_func import nimatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in VR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '94_PY_PRE.mat'\n",
    "data=hdf5storage.loadmat(filename)\n",
    "dFF = np.array(data['dFF_samp']) \n",
    "pos = (np.array(data['pos'])*360/9)\n",
    "lap = np.array(data['lap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some variables captured by the VR system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot position\n",
    "plt.plot(pos)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot laps\n",
    "plt.plot(lap)\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('lap counter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dFF,S,C\n",
    "dFF_flag=True # if using dFF or C, otherwise S\n",
    "dFF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all variables align\n",
    "print(len(pos))\n",
    "print(len(lap))\n",
    "print(dFF.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate speed of mouse indirectly with Kalman filter: \n",
    "\n",
    "# construct new pos array for Kalman filter, because position for one lap is recorded from -180 cm to 180 cm\n",
    "# i.e. the position vector jumps from -180 cm to 180 cm at the 'seam' of the belt, i.e. in one timestep.\n",
    "# Due to the spot where this seam is, the Kalman filter would interpolate a super high speed if we dind't transform\n",
    "# the position in terms of continuing with 181 cm... after 180 cm instead of -180 cm.\n",
    "\n",
    "\n",
    "idx = []\n",
    "pos1 = pos+abs(min(pos))\n",
    "for k in range(0,len(pos)-1):\n",
    "    if pos[k]>4 and pos[k+1]<-4:\n",
    "        idx.append(k)\n",
    "idx.append(len(pos1))\n",
    "        \n",
    "pos2 = []\n",
    "\n",
    "for k in range(0,len(idx)):\n",
    "    if k == 0: \n",
    "        pos2.append(pos1[0:idx[k]].tolist())\n",
    "    else: \n",
    "        pos2.append(np.array(pos1[idx[k-1]+1:idx[k]]+pos2[k-1][len(pos2[k-1])-1]).tolist())\n",
    "\n",
    "pos2 = np.concatenate(pos2).flatten() \n",
    "\n",
    "\n",
    "# One predicts both position and velocity and then compares it with real measured position to update your prediction \n",
    "# for the state, which also includes the speed.\n",
    "\n",
    "# Unit of speed is cm/s and unit of position is cm.\n",
    "\n",
    "# Initialize mean of state variable x. \n",
    "# First row is initial position and second row is initial velocity. \n",
    "x = np.array([[pos2[0]],[0]])\n",
    "\n",
    "# initialize covariance of x: \n",
    "P = np.array([[1,0],[0,100]])\n",
    "\n",
    "# time step = 1/Framerate\n",
    "dt = 0.05 #seconds\n",
    "\n",
    "\n",
    "# Following physics, the prediction is: mean(pos') = mean(pos)*v*dt and mean(v') = mean(v)+mean(1/2*a*dt^2). \n",
    "# Approximation: a (which we don't know) comes from a normal distribution around 0 with variance 1. \n",
    "# --> prediction for updated mean of state GRV-> x' = F*x\n",
    "\n",
    "# Prediction for updated covariance of state x: \n",
    "# P' = F*P*F_trans + G*G_trans where G = [[1/2*dt^2],[dt]] ,  G*G_trans = Q\n",
    "\n",
    "F = np.array([[1,dt],[0,1]]) #'Transition'-Matrix\n",
    "\n",
    "Q = np.array([[1/4*dt**4,1/2*dt**3],[1/2*dt**3,dt**2]])\n",
    "\n",
    "H = np.array([1,0]).reshape(1,2) #measurement function: We only measure position\n",
    "\n",
    "I = np.eye(2) #2D identity matrix\n",
    "\n",
    "R = np.array([1**(-3)]) # variance of measurement noise \n",
    "\n",
    "posF = np.zeros(len(pos))\n",
    "vF = np.zeros(len(pos))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for k in range(0,len(pos2)):\n",
    "    \n",
    "    # Prediction step (See explanation above):\n",
    "    x = F.dot(x)\n",
    "    P = F.dot(P).dot(F.T)+Q\n",
    "    \n",
    "    # Measurement step (Incorporate knowledge about real position to update prediction.\n",
    "    # It's done for every measurement, i.e. every frame):\n",
    "    z = pos2[k]\n",
    "    y = z -H.dot(x) # 'Innovation' between mean state prediction and measurement (we only measure position)\n",
    "    S = (H.dot(P).dot(H.T)+R) # Innovation-covariance with measurement-covariance/ uncertainty R.\n",
    "    \n",
    "    K = P.dot(H.T)*np.linalg.inv(S) # 'Kalman-Gain'= Kalman Gain = Uncertainty in predicted state divided by\n",
    "    #(Uncertainty in predicted state + Uncertainty in measurement readings). So update is weighted more when the \n",
    "    # measurement uncertainty is small. \n",
    "    \n",
    "    \n",
    "    # Update step: \n",
    "    x = x+(K.dot(y))\n",
    "    P=(I-K.dot(H)).dot(P)\n",
    "    \n",
    "    \n",
    "    posF[k] = x[0] # can be used to test the initializazion\n",
    "    vF[k] = x[1]\n",
    "\n",
    "v = vF # Speed in cm/s\n",
    "distance = pos2\n",
    "\n",
    "#plot runned distance and velocity\n",
    "fig = plt.figure(constrained_layout = True,figsize=(10,8))\n",
    "ax = fig.add_gridspec(2,1)\n",
    "ax1 = fig.add_subplot(ax[0,0:2])\n",
    "ax2 = fig.add_subplot(ax[1,0:2])\n",
    "ax1.set_title('Distance')\n",
    "ax1.plot(distance)\n",
    "ax1.set_xlabel('frames')\n",
    "ax1.set_ylabel('distance in in cm')\n",
    "ax2.set_title('Velocity')\n",
    "ax2.set_xlabel('frames')\n",
    "ax2.set_ylabel('velocity in cm/s')\n",
    "ax2.plot(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore your cell traces!\n",
    "Plot dF/F, deconvolved traces as well as infered spikes for a couple of components here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellToPlot=1\n",
    "fig = plt.figure(figsize=(10,3),constrained_layout = True)\n",
    "ax = fig.add_gridspec(1,2)\n",
    "ax1 = fig.add_subplot(ax[0,0:2])\n",
    "\n",
    "ax1.plot(dFF[cellToPlot,:])\n",
    "ax1.set_ylabel('dFF')\n",
    "ax1.set_xlabel('frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us now find some place cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for place Cell identification:\n",
    "\n",
    "lengthBelt = 360 # (in cm)\n",
    "numberOfBinBorders = 46\n",
    "\n",
    "widthOfBin = lengthBelt/numberOfBinBorders  #in cm.\n",
    "print('width of Bin = '+str(widthOfBin)+'cm')\n",
    "pos=pos+(360/2)\n",
    "posBin = np.arange((min(pos)),(max(pos)),widthOfBin) \n",
    "numCells = int(len(dFF))\n",
    "v_thresh = 2\n",
    "numLaps = int(max(lap))\n",
    "numBins = len(posBin)-1\n",
    "run_only = True #Determines if signal is only binned, when mouse is running\n",
    "print('numBins = '+str(numBins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine mean dFF in each bin in each lap. Also produce binned signal which is normalized with the duration per bin\n",
    "\n",
    "def assign_dFF(dFF_signal):\n",
    "    \n",
    "    dFFInBinAll = np.zeros((numLaps,numBins))\n",
    "    durInBinAll = np.zeros((numLaps,numBins))\n",
    "    dFFInBinAllNormalized = np.zeros((numLaps,numBins))\n",
    "    occupancy = [0]*numLaps\n",
    "    \n",
    "    for l in range(0,numLaps):\n",
    "        \n",
    "        for b in range(1,numBins+1):\n",
    "\n",
    "            BinIdx1 = np.where(pos>posBin[b-1])[0]\n",
    "            BinIdx = np.where(pos<posBin[b])[0]\n",
    "            LapIdx = np.where(lap==l+1)[0]\n",
    "            vIdx = np.where(v>v_thresh)[0]\n",
    "            \n",
    "            if run_only:\n",
    "                Idx = list(set(BinIdx1).intersection(BinIdx,LapIdx,vIdx)) \n",
    "            else: \n",
    "                Idx = list(set(BinIdx1).intersection(BinIdx,LapIdx))\n",
    "            \n",
    "            \n",
    "            dFFPerBin = dFF_signal[Idx]\n",
    "            durPerBin = len(Idx)\n",
    "            \n",
    "\n",
    "            if durPerBin>0:     \n",
    "                dFFInBinAll[l][b-1] = np.nanmean(dFFPerBin)\n",
    "                durInBinAll[l][b-1] = durPerBin \n",
    "            else: \n",
    "                dFFInBinAll[l][b-1] = float('nan')\n",
    "                durInBinAll[l][b-1] = 0\n",
    "        \n",
    "        occupancy[l] = np.array(durInBinAll[l])/sum(durInBinAll[l])\n",
    "        dFFInBinAllNormalized[l] = dFFInBinAll[l]*occupancy[l]\n",
    "        \n",
    "        \n",
    "    meanDFF = np.nanmean(dFFInBinAll,axis = 0) \n",
    "    meanDFFNormalized = meanDFF*np.nanmean(occupancy,axis = 0)    \n",
    "    \n",
    "    meanDur = np.nanmean(durInBinAll,axis = 0)\n",
    "\n",
    "    return dFFInBinAll, dFFInBinAllNormalized, meanDFF, meanDFFNormalized, meanDur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to speed up the rest of analysis, we dont look at all cells\n",
    "numCells=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#assign dFF for all cells, if this is slow adjust the numCells variable\n",
    "\n",
    "dFFInBinAll = [0]*numCells\n",
    "dFFInBinAllNormalized = [0]*numCells\n",
    "meanDFF = [0]*numCells \n",
    "meanDFFNormalized = [0]*numCells\n",
    "meanDur = [0]*numCells\n",
    "\n",
    "\n",
    "for c in range(0,numCells):\n",
    "    print('cell ' + str(c+1))\n",
    "    dFFInBinAll[c], dFFInBinAllNormalized[c], meanDFF[c], meanDFFNormalized[c], meanDur[c] = \\\n",
    "    assign_dFF(dFF[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dFF over laps\n",
    "PosBin=np.array(dFFInBinAllNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellIdx = 4\n",
    "plt.imshow(PosBin[cellIdx],interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the normalized binned signal for individual cells:\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(np.linspace(0,lengthBelt,numBins),meanDFFNormalized[cellIdx],label ='Signal')\n",
    "x = np.linspace(0,lengthBelt,numBins)\n",
    "plt.plot(x,[np.mean(meanDFFNormalized[cellIdx])]*numBins,label='Mean')\n",
    "plt.ylabel('amplitude')\n",
    "plt.xlabel('Belt in cm')\n",
    "\n",
    "if dFF_flag == True:\n",
    "    plt.title('Position binned dFF-Signal of cell '+str(cellIdx) +' averaged over laps')\n",
    "    plt.legend(loc='upper right')\n",
    "else:\n",
    "    plt.title('Position binned S-Signal of cell '+str(cellIdx) +' averaged over laps')\n",
    "    plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate placescore for each cell: \n",
    "def calculate_placescore(dFFPerBin,durPerBin):\n",
    "        \n",
    "        placescore = 0\n",
    "\n",
    "        for i in range(1,numBins):\n",
    "            \n",
    "            occupancy = durPerBin[i]/sum(durPerBin[1:])\n",
    "\n",
    "            incr = occupancy*(dFFPerBin[i]/np.nanmean(dFFPerBin))\\\n",
    "            *np.real(np.log2(dFFPerBin[i]/np.nanmean(dFFPerBin)))\n",
    "\n",
    "            if not np.isnan(incr):\n",
    "                placescore = placescore+incr\n",
    "                \n",
    "        return placescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeScore = [0]*numCells\n",
    "occupancy=[0]*numCells\n",
    "for c in range(0,numCells):\n",
    "    placeScore[c] = calculate_placescore(meanDFF[c],meanDur[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Polar Analysis:\n",
    "\n",
    "# Put position binned siganl in a circle and calculate the centroid.\n",
    "# If centroid is far from origin of polar coordinate system, it's likely that we have a placecell. \n",
    "\n",
    "def polar_analysis(dFFPerBin):\n",
    "   \n",
    "    dFFPerBin = dFFPerBin/np.nanmean(dFFPerBin) # normalize with mean of dFF per Bin\n",
    "\n",
    "    nanidx = np.array(np.where(dFFPerBin==np.nan))\n",
    "\n",
    "    # Interpolate for possible Nans. Otherwise polygon would be distorted and yield a misleading centroid\n",
    "    t = np.linspace(0,2*np.pi,len(dFFPerBin))\n",
    "\n",
    "    if not nanidx.size ==0:\n",
    "        dFFPerBin[nanidx] = np.interp(t[nanidx],t[np.arange(len(t))!=nanidx].flatten(),\\\n",
    "                                   signal[np.arange(len(dFFPerBin))!=nanidx].flatten())\n",
    "\n",
    "    # convert from polar to cartesian, because the polygon function requires cartesian coordinates.\n",
    "    x = dFFPerBin*np.cos(t)\n",
    "    y = dFFPerBin*np.sin(t)\n",
    "\n",
    "    # calculate centroid and convert to polar coordinates to get rho:\n",
    "    poly = Polygon(np.array([x,y]).T)\n",
    "    centroid = poly.centroid # in cartesian coordinates\n",
    "    \n",
    "    #convert to polar coordinates to get rho and normalize with mean dFF signal of cell \n",
    "    centroidRho = np.sqrt(np.array(centroid)[0]**2+np.array(centroid)[1]**2)\n",
    "    \n",
    "    return poly,centroid,centroidRho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = [0]*numCells\n",
    "centroid = [0]*numCells\n",
    "centroidRho = [0]*numCells\n",
    "\n",
    "for c in range(0,numCells):\n",
    "    poly[c], centroid[c], centroidRho[c] = polar_analysis(meanDFFNormalized[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellIdx = 3\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(*poly[cellIdx].exterior.xy,'.',label='Polygon Edges',markersize = 10)\n",
    "plt.plot(np.array(centroid[cellIdx])[0],np.array(centroid[cellIdx])[1],'.',label = 'Centroid',markersize=20)\n",
    "plt.plot(0,0,'.',label='Origin',markersize = 18)\n",
    "plt.title('cell '+str(cellIdx)+' Polygon with centroid')\n",
    "plt.legend()\n",
    "\n",
    "print(np.mean(meanDFFNormalized[cellIdx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare place score and rho across cells\n",
    "\n",
    "fig = plt.figure(constrained_layout = True,figsize=(10,8))\n",
    "ax = fig.add_gridspec(2,2)\n",
    "ax1 = fig.add_subplot(ax[0,0:2])\n",
    "ax2 = fig.add_subplot(ax[1,0:2])\n",
    "ax1.set_title('PlaceScore')\n",
    "ax1.plot(placeScore)\n",
    "ax1.set_xlabel('cell')\n",
    "ax1.set_ylabel('PlaceScore')\n",
    "ax2.set_title('Centroid_Rho')\n",
    "ax2.set_xlabel('cell')\n",
    "ax2.set_ylabel('Centroid_Rho')\n",
    "ax2.plot(centroidRho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shuffle/ bootstrap to get percentile in the probability distribution that placescore was by chance:\n",
    "# (when value is far out from distribution mean, i.e. percentile >0.95 it's most likely not a placeencoding by chance,\n",
    "# i.e. we have a placecell.)\n",
    "\n",
    "shift_minrange = 500\n",
    "shift_maxrange = len(pos)\n",
    "nshuffle = 10\n",
    "\n",
    "shiftframes = [int(x) for x in np.around(((shift_minrange+np.random.rand(1,nshuffle)*\\\n",
    "                                           (shift_maxrange-shift_minrange))[0]),0)]\n",
    "\n",
    "meandFFshuffled = np.zeros((nshuffle,len(dFF)))\n",
    "\n",
    "placeScoreShuffled = np.zeros((numCells,nshuffle))\n",
    "dFFInBinShuffled = np.zeros((int(max(lap)),numBins))\n",
    "\n",
    "for c in range(0,numCells):\n",
    "    print('cell ' + str(c+1))\n",
    "    for n in range(0,nshuffle):\n",
    "\n",
    "        #shift whole dFF for a random distance between 500 and len(pos)\n",
    "        dFFShifted = np.roll(dFF[c],shiftframes[n])\n",
    "\n",
    "\n",
    "        # Create (here n_laps*2) chunks of shifted dFF \n",
    "        # (the smaller the chunks the 'better shuffled')\n",
    "        #Add such that array is dividible by 2*max(lap)\n",
    "        \n",
    "        filler = np.repeat(float('nan'),np.mod(-len(dFFShifted),int(2*max(lap)))) \n",
    "        dFFShiftedChunked = np.reshape(np.append(dFFShifted,filler),(int(2*max(lap)),-1))\n",
    "        \n",
    "        permutationIndices = np.random.permutation(int(2*max(lap)))\n",
    "        \n",
    "        dFFPermutedChunked = dFFShiftedChunked[permutationIndices][:]\n",
    "          \n",
    "        dFFPermuted = np.reshape(dFFPermutedChunked,(len(dFFShifted)+len(filler),-1))\n",
    "        \n",
    "        _ , _ , dFFInBinShuffled , _ , _ = assign_dFF(dFFPermuted)\n",
    "        \n",
    "        placeScoreShuffled[c][n] = calculate_placescore(dFFInBinShuffled,meanDur[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and save PlaceScore percentile (PlaceScorePct): \n",
    "\n",
    "placeScorePct = [0]*numCells\n",
    "\n",
    "for c in range(0,numCells):\n",
    "    nless = sum(placeScoreShuffled[c]<placeScore[c])\n",
    "    nequal = sum(placeScoreShuffled[c]==placeScore[c])\n",
    "    placeScorePct[c] = (nless + 0.5*nequal)/(len(placeScoreShuffled[c]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place cell from percentile > placeThreshold\n",
    "\n",
    "placeThreshold = 0.95\n",
    "\n",
    "\n",
    "if dFF_flag == True: \n",
    "    \n",
    "    placeCellIdx_dFF = np.where(np.array(placeScorePct)>placeThreshold)\n",
    "    percPlaceCells_dFF = len(placeCellIdx_dFF[0])/len(dFF)\n",
    "    placeCellIdx_dFF = np.where(np.array(placeScorePct)>placeThreshold)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous wavelet transform to obtain placefield: \n",
    "\n",
    "def determine_placefield(cellIdx,minSmoothingLevel,maxSmoothingLevel):\n",
    "\n",
    "   \n",
    "    # Concatenate signal to take circularity of belt into account when smoothing with mexican hat convolution\n",
    "    cwtMatr = sig.cwt(np.array([meanDFFNormalized[cellIdx]]*3).flatten(), \\\n",
    "                         sig.ricker, np.arange(1, (numBins)*3)) \n",
    "\n",
    "    # Find out the 'optimal' smoothing level in the specified smoothing range for the second repetition of the signal: \n",
    "    cwtLevel = np.unravel_index(np.argmax(cwtMatr[minSmoothingLevel:maxSmoothingLevel,numBins+1:2*numBins])\\\n",
    "                                , cwtMatr[minSmoothingLevel:maxSmoothingLevel,numBins:2*numBins].shape)[0]\\\n",
    "    +int(minSmoothingLevel)\n",
    "\n",
    "    #Find peaks with prominence and width (later only use them which 'start' in second repetition of the 3 \n",
    "    #repetitions)\n",
    "    #Additional variable stand for minimum width, prominence and heigt of the peak.\n",
    "    #(For height criterium see Esteves et al. 2020)\n",
    "    cwtPeaks = sig.find_peaks(cwtMatr[cwtLevel],prominence=np.std(cwtMatr[cwtLevel]),\\\n",
    "                                 width = 2,\\\n",
    "                                 height = np.median(cwtMatr[0])+3*scipy.stats.median_abs_deviation(cwtMatr[0]))\n",
    "\n",
    "    peakPosition = cwtPeaks[0]\n",
    "    peakLeftIps = cwtPeaks[1]['left_ips']\n",
    "    peakRightIps = cwtPeaks[1]['right_ips'][:int(len(peakPosition))]\n",
    "\n",
    "    #1st dim: left borders of the placefield, 2nd dim, right border of the place field but still for the \n",
    "    #3*[signal] array\n",
    "    placeFieldEdgesFull = np.array([peakLeftIps,peakRightIps]).flatten()\n",
    "    placeFieldEdgesFull = placeFieldEdgesFull.reshape(2,int(len(placeFieldEdgesFull)/2)) \n",
    "\n",
    "    # Extract the borders for the middle of the 3 concatenated signal repetitions and shift as if it begins at 0. \n",
    "    idxPlaceFieldEdgesC1 = np.array(np.where(placeFieldEdgesFull[0]>numBins)).flatten() \n",
    "    idxPlaceFieldEdgesC2 = np.array(np.where(placeFieldEdgesFull[0]<=2*numBins)).flatten()\n",
    "    idxPlaceFieldEdges = idxPlaceFieldEdgesC1[np.in1d(idxPlaceFieldEdgesC1,idxPlaceFieldEdgesC2)]\n",
    "    placeFieldEdges = placeFieldEdgesFull[:,idxPlaceFieldEdges]-numBins\n",
    "    \n",
    "    # Force right borders to also be in the range between 0 and numBins (useful for plotting, this is taken into account \n",
    "    #later when placefields are further used)\n",
    "    for x in range(0,len(placeFieldEdges[1])):\n",
    "        if placeFieldEdges[1][x]>numBins:\n",
    "            placeFieldEdges[1][x] = placeFieldEdges[1][x]-numBins\n",
    "\n",
    "    return cwtMatr, peakPosition, cwtLevel, placeFieldEdges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot placefield for single cells\n",
    "\n",
    "minSmoothingLevel = 0\n",
    "maxSmoothingLevel = 15\n",
    "cellIdx = 3\n",
    "\n",
    "cwtMatr, peakPosition, cwtLevel, placeFieldEdges = determine_placefield(cellIdx,minSmoothingLevel,maxSmoothingLevel)\n",
    "\n",
    "idxRight = np.array([int(round(x)) for x in placeFieldEdges[1]])\n",
    "idxLeft = np.array([int(round(x)) for x in placeFieldEdges[0]])\n",
    "\n",
    "fig = plt.figure(figsize=(10,8),constrained_layout = True)\n",
    "ax = fig.add_gridspec(3,2)\n",
    "ax1 = fig.add_subplot(ax[0,0:2])\n",
    "ax2 = fig.add_subplot(ax[1,0:2])\n",
    "ax3 = fig.add_subplot(ax[2,0:2])\n",
    "\n",
    "\n",
    "# Plot wavelet transform for all possible levels in the level range and mark 'optimal' level.\n",
    "ax1.imshow(cwtMatr[:maxSmoothingLevel+10,numBins:2*numBins],interpolation = 'none',aspect='auto')\n",
    "ax1.plot(np.linspace(0,numBins,numBins),[cwtLevel]*numBins,color = 'w',linestyle = '--')\n",
    "ax1.set_title('Cwt Level')\n",
    "ax1.set_xlabel('Bins')\n",
    "ax1.set_ylabel('Scale')\n",
    "\n",
    "\n",
    "# Plot mean position binned signal over all laps and the transformed signal \n",
    "ax2.plot(cwtMatr[cwtLevel][numBins:numBins*2],label='transformed signal')\n",
    "ax2.plot(meanDFFNormalized[cellIdx], label = 'mean signal')\n",
    "if not np.array(idxRight).size == 0:\n",
    "    ax2.plot(placeFieldEdges[0],meanDFFNormalized[cellIdx][idxLeft] ,marker = 'o',linestyle = 'None',color='r',\\\n",
    "           label = 'Left border of PF')\n",
    "    ax2.plot(placeFieldEdges[1],meanDFFNormalized[cellIdx][idxRight] ,marker = 'o',linestyle = 'None',color='b',label\\\n",
    "           = 'Right border of PF')\n",
    "ax2.legend(loc = 'upper left')\n",
    "ax2.set_xlabel('Bins')\n",
    "ax2.set_ylabel('Signal')\n",
    "ax2.set_title('Mean and transformed signal  PlaceScorePct = '+str(placeScorePct[cellIdx]))\n",
    "\n",
    "\n",
    "# Plot different laps:\n",
    "for l in range(0,numLaps):\n",
    "    ax3.plot(dFFInBinAllNormalized[cellIdx][l],label='lap '+str(l+1))\n",
    "\n",
    "\n",
    "if not np.array(idxRight).size==0:\n",
    "    ax3.plot(placeFieldEdges[0],meanDFFNormalized[cellIdx][idxLeft] \\\n",
    "           ,marker = 'o',linestyle = 'None',color='r',\\\n",
    "           label = 'Left border of PF')\n",
    "    idxRight = [int(x) for x in placeFieldEdges[1]]\n",
    "    ax3.plot(placeFieldEdges[1],meanDFFNormalized[cellIdx][idxRight] \\\n",
    "           ,marker = 'o',linestyle = 'None',color='b',label \\\n",
    "           = 'Right border of PF')\n",
    "    \n",
    "ax3.set_title('Raw signals over laps  PlaceScorePct = '+str(placeScorePct[cellIdx]))\n",
    "ax3.legend(loc = 'upper left')\n",
    "ax3.set_xlabel('Bins')\n",
    "ax3.set_ylabel('signal')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If placefield was detected: For how many laps is mean in placefields higher than (K times) the mean \n",
    "#outside of PF?\n",
    "\n",
    "\n",
    "K = 1.5\n",
    "\n",
    "numPlaceCodedLaps = [0]*numCells\n",
    "\n",
    "for c in range(0,numCells):\n",
    "    \n",
    "    inPF = []\n",
    "    outPF = []\n",
    "    cwtMatr, peakPosition, cwtLevel, placeFieldEdges = determine_placefield(c,minSmoothingLevel,maxSmoothingLevel)\n",
    "    idxRight = np.array([int(np.floor(x)) for x in placeFieldEdges[1]])\n",
    "    idxLeft = np.array([int(np.floor(x)) for x in placeFieldEdges[0]])\n",
    "    \n",
    "    for k in range(0,len(idxRight)): # for all place fields per cell\n",
    "\n",
    "        interval = []\n",
    "        intervalWidth = idxRight[k]-idxLeft[k]\n",
    "\n",
    "\n",
    "        #In case the field spans the edge between last and first bin (note circularity of treadmill)\n",
    "        if intervalWidth <0: \n",
    "            interval = np.concatenate((np.linspace(idxLeft[k],numBins-1,numBins-idxLeft[k]),\\\n",
    "                                    np.linspace(0,idxRight[k],idxRight[k]+1)),axis=None)\n",
    "\n",
    "        else: \n",
    "            interval = np.concatenate((np.linspace(idxLeft[k],idxRight[k],idxRight[k]-idxLeft[k]+1)),axis=None)                              \n",
    "\n",
    "        interval = [int(x) for x in interval]\n",
    "        inPF = inPF+interval\n",
    "\n",
    "        for m in range(0,numBins):\n",
    "            if m not in np.array(inPF).flatten():\n",
    "                outPF.append(int(m))\n",
    "\n",
    "    for l in range(0,numLaps):\n",
    "        if np.nanmean(np.array(dFFInBinAllNormalized)[c][l][inPF]) > \\\n",
    "        K*np.nanmean(np.array(dFFInBinAllNormalized)[c][l][outPF]):\n",
    "            numPlaceCodedLaps[c]= numPlaceCodedLaps[c]+1\n",
    "\n",
    "if dFF_flag == True:\n",
    "    stablePlaceFieldCells_dFF = np.where(np.array(numPlaceCodedLaps)>=np.round(0.8*numLaps))\n",
    "else:\n",
    "    stablePlaceFieldCells_S = np.where(np.array(numPlaceCodedLaps)>=np.round(0.8*numLaps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed_tuning: Linear regression of dFF as a function of mouse speed plus goodness of fit (i.e.'speedscore'):\n",
    "\n",
    "widthOfSpeedBin = max(v)/100\n",
    "print('Width of speed bin = '+str(widthOfSpeedBin)+' cm/s')\n",
    "\n",
    "speedBin = np.arange((min(v)),(max(v)),widthOfSpeedBin) \n",
    "numSpeedBins = len(speedBin)-1\n",
    "    \n",
    "def assign_speedBins(dFF_signal):\n",
    "    \n",
    "      \n",
    "    dFFPerSpeedBinNormalized = [0]*numSpeedBins\n",
    "    \n",
    "    for b in range(1,numSpeedBins+1):\n",
    "\n",
    "        BinIdx1 = np.where(v>speedBin[b-1])[0]\n",
    "        BinIdx = np.where(v<speedBin[b])[0]\n",
    "\n",
    "        Idx = list(set(BinIdx1).intersection(BinIdx))\n",
    "\n",
    "        dFFPerSpeedBin = dFF_signal[Idx]\n",
    "        durPerSpeedBin = len(Idx)\n",
    "        dFFPerSpeedBinNormalized[b-1] = np.nanmean(dFFPerSpeedBin/durPerSpeedBin)\n",
    "\n",
    "    \n",
    "    return dFFPerSpeedBinNormalized    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,a,b):\n",
    "    f = a*x+b\n",
    "    return f\n",
    "\n",
    "def speed_regression(signal,v):\n",
    "   \n",
    "    # do linear regression:\n",
    "    x = v\n",
    "    y = signal\n",
    "    popt, pcov = curve_fit(f,x,y)\n",
    "    \n",
    "    # compute r2:\n",
    "    r2 = 1.0-(sum((y-f(x,*popt))**2)/((n-1.0)*np.var(y,ddof=1)))\n",
    "\n",
    "    \n",
    "    return popt, pcov, r2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellIdx = 1\n",
    "\n",
    "x = speedBin[1:]\n",
    "speedBinnedSignal = assign_speedBins(dFF[cellIdx])\n",
    "y = speedBinnedSignal\n",
    "n = len(y)\n",
    "\n",
    "popt, pcov, r2 = speed_regression(y,x)\n",
    "\n",
    "\n",
    "# plotting:\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(x,f(x,*popt), label = 'regression line')\n",
    "plt.plot(x,y,'.',label = 'data',markersize = 12)\n",
    "plt.title('R2 = '+ str(r2), fontsize = 15)\n",
    "plt.xlabel('speed in cm/s' , fontsize = 13)\n",
    "plt.ylabel('dF/F in %', fontsize = 13)\n",
    "\n",
    "# compute the confidence intervals:\n",
    "\n",
    "a,b = unc.correlated_values(popt, pcov)\n",
    "std = unp.std_devs(f(x,a,b))\n",
    "nom = unp.nominal_values(f(x,a,b))\n",
    "plt.plot(x, nom + 1.96 * std, c='red', label = 'confidence interval')\n",
    "plt.plot(x, nom - 1.96 * std, c='red')\n",
    "\n",
    "\n",
    "plt.legend(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check R2 for all cells\n",
    "x = speedBin[1:]\n",
    "r2 = [0]*numCells\n",
    "for c in range(0,numCells):\n",
    "    \n",
    "    speedBinnedSignal = assign_speedBins(dFF[c])\n",
    "    y = speedBinnedSignal\n",
    "    n = len(y)\n",
    "    _, _, r2[c] = speed_regression(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot speed R2\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(r2)\n",
    "plt.ylabel('R2', fontsize = 15)\n",
    "plt.xlabel('cell', fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place score and speed score as a function of the number of neurons: \n",
    "\n",
    "#plt.hist(r2)\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "ax = fig.add_gridspec(2,1)\n",
    "plt.hist(placeScore)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
